{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture Link - https://www.youtube.com/playlist?list=PLl1irxoYh2wyLwJutUZx5Q_QEEDZoXBnz\n",
        "\n",
        "# Code - https://github.com/blackdew/ml-tensorflow"
      ],
      "metadata": {
        "id": "AtpdruBP_vN4"
      },
      "id": "AtpdruBP_vN4"
    },
    {
      "cell_type": "markdown",
      "id": "spare-blowing",
      "metadata": {
        "id": "spare-blowing"
      },
      "source": [
        "# 지도학습\n",
        "## 순서\n",
        "### 1. 과거의 데이터 준비\n",
        "### 2. 모델의 구조 만들기\n",
        "### 3. 데이터로 모델을 학습(fit) 시키기\n",
        "### 4. 모델 이용\n",
        "#### Fit -> 모델을 데이터에 맞게 피팅하는 것(학습)\n",
        "\n",
        "##### 원인이 되는 변수 -> 독립 변수\n",
        "##### 결과가 되는 변수 -> 종속 변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "individual-wheel",
      "metadata": {
        "id": "individual-wheel"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# co_accuracy = pd.read_csv('C:\\\\Users\\\\hhshi\\\\OneDrive\\\\바탕 화면\\\\CO오염도_최종.csv',encoding = 'utf-8')\n",
        "lemonade = pd.read_csv('C:\\\\신현호\\\\2022년_머러공부\\\\youtube\\\\dataset\\\\lemonade.csv',encoding='utf-8')\n",
        "boston = pd.read_csv('C:\\\\신현호\\\\2022년_머러공부\\\\youtube\\\\dataset\\\\boston.csv')\n",
        "iris = pd.read_csv('C:\\\\신현호\\\\2022년_머러공부\\\\youtube\\\\dataset\\\\iris.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lightweight-little",
      "metadata": {
        "id": "lightweight-little",
        "outputId": "54601a8a-2fc1-4491-ca18-a6d4b4ea3c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['온도', '판매량'], dtype='object')\n",
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n",
            "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(lemonade.columns)\n",
        "print(boston.columns)\n",
        "print(iris.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "necessary-spoke",
      "metadata": {
        "id": "necessary-spoke"
      },
      "source": [
        "# Lemonade sale prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "framed-study",
      "metadata": {
        "id": "framed-study",
        "outputId": "0d3e81d0-9bc3-4b7b-8dad-f86290bf2310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   온도\n",
            "0  20\n",
            "1  21\n",
            "2  22\n",
            "3  23\n",
            "4  24\n",
            "5  25\n",
            "   판매량\n",
            "0   40\n",
            "1   42\n",
            "2   44\n",
            "3   46\n",
            "4   48\n",
            "5   50\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 독립, 종속 변수 나누기 (컬럼 별로 값 가져오기)\n",
        "# lemonade\n",
        "ind_var = lemonade[['온도']]\n",
        "dep_var = lemonade[['판매량']]\n",
        "print(ind_var)\n",
        "print(dep_var)\n",
        "type(ind_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cutting-doctor",
      "metadata": {
        "id": "cutting-doctor"
      },
      "outputs": [],
      "source": [
        "# Making structure of model\n",
        "X = tf.keras.layers.Input(shape=[1]) # 숫자가 1인 이유 -> 독립변수가 한 개이기 때문이다.\n",
        "Y = tf.keras.layers.Dense(1)(X) # 숫자가 1인 이유 -> 마찬가지로 종속 변수가 한 개이기 때문이다.\n",
        "model = tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "textile-marine",
      "metadata": {
        "id": "textile-marine"
      },
      "source": [
        "# Loss\n",
        "## (독립 변수를 모델에 넣어서 나온 예측값들- 실제 결과)^2 들의 평균 값 (mse 사용 시)\n",
        "## 따라서, Loss가 0에 가까워질수록 학습이 잘 된 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "western-liechtenstein",
      "metadata": {
        "id": "western-liechtenstein",
        "outputId": "3710ed51-82b0-460b-9d2c-261f9e0e332e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1f0fee10910>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(ind_var, dep_var, epochs=1000,verbose=0)  # epochs -> 모델을 몇 번 학습할 지\n",
        "# verbose를 0으로 설정하면 일일히 출력값을 출력하는 일이 없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "instructional-riding",
      "metadata": {
        "id": "instructional-riding",
        "outputId": "97bda9c7-06b2-4fe5-e803-14a586565b81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[39.989586],\n",
              "       [41.98905 ],\n",
              "       [43.988518],\n",
              "       [45.98798 ],\n",
              "       [47.987446],\n",
              "       [49.98691 ]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(ind_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collect-reunion",
      "metadata": {
        "id": "collect-reunion",
        "outputId": "14cc1043-ac62-4d40-9be9-4e5f43a4eb7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>판매량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   판매량\n",
              "0   40\n",
              "1   42\n",
              "2   44\n",
              "3   46\n",
              "4   48\n",
              "5   50"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dep_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rapid-conspiracy",
      "metadata": {
        "id": "rapid-conspiracy",
        "outputId": "2f67f73f-7310-489c-b647-2a71d7e07f08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[29.992268]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict([[15]]) # 15도일 때의 판매량 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "honey-blind",
      "metadata": {
        "id": "honey-blind"
      },
      "source": [
        "# Boston housing price prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alpine-temple",
      "metadata": {
        "id": "alpine-temple",
        "outputId": "1911086c-d245-4a32-cdcf-df367308ac28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'b', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boston.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-march",
      "metadata": {
        "id": "banned-march",
        "outputId": "23683a7c-1ae0-4a49-8e6e-d46fc76e66bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
              "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
              "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
              "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
              "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
              "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
              "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
              "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
              "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
              "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
              "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
              "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
              "\n",
              "     ptratio       b  lstat  medv  \n",
              "0       15.3  396.90   4.98  24.0  \n",
              "1       17.8  396.90   9.14  21.6  \n",
              "2       17.8  392.83   4.03  34.7  \n",
              "3       18.7  394.63   2.94  33.4  \n",
              "4       18.7  396.90   5.33  36.2  \n",
              "..       ...     ...    ...   ...  \n",
              "501     21.0  391.99   9.67  22.4  \n",
              "502     21.0  396.90   9.08  20.6  \n",
              "503     21.0  396.90   5.64  23.9  \n",
              "504     21.0  393.45   6.48  22.0  \n",
              "505     21.0  396.90   7.88  11.9  \n",
              "\n",
              "[506 rows x 14 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boston = boston.dropna(axis=1)\n",
        "boston"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hawaiian-recipient",
      "metadata": {
        "id": "hawaiian-recipient",
        "outputId": "e1d9e26e-efef-43fc-93f2-70c0c9a65262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 13) (506, 1)\n"
          ]
        }
      ],
      "source": [
        "ind_var_boston = boston[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
        "       'ptratio', 'b', 'lstat']]\n",
        "dep_var_boston = boston[['medv']]\n",
        "print(ind_var_boston.shape, dep_var_boston.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "universal-bangladesh",
      "metadata": {
        "id": "universal-bangladesh"
      },
      "outputs": [],
      "source": [
        "# 모델 구조\n",
        "X = tf.keras.layers.Input(shape=[13])\n",
        "Y = tf.keras.layers.Dense(1)(X) \n",
        "model_bos = tf.keras.models.Model(X,Y)\n",
        "model_bos.compile(loss='mse')\n",
        "\n",
        "# 13개의 입력으로 1개의 출력을 만들어내는 구조\n",
        "# 13개의 입력층, 1개의 출력층\n",
        "# y = w1x1 + w2x2 + .... + w13x13+b\n",
        "\n",
        "# 만약 12개의 입력층과 2개의 출력층이라면?\n",
        "# y1 = w1x1+ .... + w12x12 + b\n",
        "# y2 = w1x1 + ... + w12x12 + b \n",
        "\n",
        "# 첫번 째 수식에서 w 12개, b 1개\n",
        "# 두번째 수식에서 w 12개, b 1개 총 26개의 숫자 찾아야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "missing-egypt",
      "metadata": {
        "id": "missing-egypt",
        "outputId": "ce0340f7-4a0c-4091-9cb1-b0db6806a4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0355\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 666us/step - loss: 23.2641\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8060\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2717\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0567\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.1733\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 734us/step - loss: 22.5783\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4687\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2211\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.6950\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.5244\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9328\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 933us/step - loss: 23.0371\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 934us/step - loss: 22.9539\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 812us/step - loss: 23.5510\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 22.8060\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3516\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1616\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9048\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3388\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9920\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.2631\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2105\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1136\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.5069\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3197\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2414\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0169\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0984\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 666us/step - loss: 23.1283\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9576\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1891\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1225\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0403\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0494\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8066\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0429\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2945\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8297\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 805us/step - loss: 23.1271\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3387\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 27.88 - 0s 532us/step - loss: 23.0470\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1610\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2027\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.8068\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0274\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1577\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4342\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2009\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9782\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0965\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 534us/step - loss: 22.9053\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4734\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2793\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 534us/step - loss: 23.1760\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.7431\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.3640\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1636\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.2697\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 732us/step - loss: 22.8972\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4557\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1168\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8565\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2227\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1957\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9891\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 22.9867\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9926\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0355\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9042\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0206\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.6913\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0514\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0667\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9434\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8014\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.1527\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3240\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4081\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9310\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3054\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.7657\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3618\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0277\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1718\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 0s 867us/step - loss: 23.4352\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 0s 933us/step - loss: 23.1612\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 0s 735us/step - loss: 23.0769\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8911\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9252\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1618\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9299\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2137\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 0s 736us/step - loss: 22.8629\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.6229\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9078\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1776\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0360\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 0s 601us/step - loss: 22.9173\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2971\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.5214\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0295\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9500\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2012\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9288\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0004\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7814\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1961\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0615\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3423\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4704\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.2100\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.4194\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0536\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.6464\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8615\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.5260\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4913\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8814\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9878\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1424\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2332\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.5796\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9461\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7720\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.5116\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2095\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9538\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.5254\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3621\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1669\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4382\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0263\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3096\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6779\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9873\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2828\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0785\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3833\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7558\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 0s 401us/step - loss: 22.7718\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8970\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0375\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7817\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9492\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1981\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0014\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6362\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.4079\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3734\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0320\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.5697\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4614\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0230\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2936\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9099\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0194\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0616\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2951\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1684\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9916\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1194\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2064\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3099\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.5108\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.4560\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0317\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0886\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3305\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0513\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.4306\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0198\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7504\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 0s 492us/step - loss: 23.2295\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.2335\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2578\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1657\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0300\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1526\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7550\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.6880\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9014\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.1270\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3814\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1045\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2793\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0191\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7673\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7162\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4319\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9460\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9450\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9135\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3804\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1003\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1159\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8778\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.5033\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9096\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3701\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7672\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9621\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.2594\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0291\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3918\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.6679\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2927\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7657\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0172\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 0s 736us/step - loss: 22.6597\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2589\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2289\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2475\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0411\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9432\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1968\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 0s 666us/step - loss: 23.1923\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9071\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3210\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.8964\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8321\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2108\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0000\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2528\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.6473\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3289\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7926\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9683\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0027\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 19.85 - 0s 400us/step - loss: 23.1834\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1413\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9945\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1457\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2595\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9417\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0364\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6960\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9778\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1620\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 0s 333us/step - loss: 23.1627\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0998\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0192\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0233\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7415\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3370\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3102\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2482\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7763\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.5071\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1885\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9464\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2042\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1506\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8613\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.6825\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1092\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8694\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3151\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6900\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9345\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3808\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.5432\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0768\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.6031\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 0s 631us/step - loss: 22.9598\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2919\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8020\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1379\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2945\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8171\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.7937\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3632\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 0s 333us/step - loss: 23.0372\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9713\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0560\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6759\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9070\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9645\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.8616\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1656\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3036\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7700\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.1862\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1397\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9577\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9533\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0788\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1905\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7262\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 0s 601us/step - loss: 23.1935\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.5306\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8800\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1711\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9844\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9574\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8562\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1152\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8901\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0043\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.7043\n",
            "Epoch 301/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7184\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2391\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1999\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9727\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.5177\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7800\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2156\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4449\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1216\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0900\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2250\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.4102\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.4793\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3013\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0702\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7158\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1495\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9813\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0289\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3911\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1629\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2831\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9995\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9491\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0867\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3836\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0962\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9463\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.8550\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4878\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0440\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8655\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.7989\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.5955\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9873\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 0s 601us/step - loss: 23.3148\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2486\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.0851\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6399\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1755\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1281\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9677\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7851\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2676\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.5070\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0358\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2774\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.4301\n",
            "Epoch 349/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1687\n",
            "Epoch 350/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1366\n",
            "Epoch 351/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0209\n",
            "Epoch 352/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2977\n",
            "Epoch 353/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9961\n",
            "Epoch 354/1000\n",
            "16/16 [==============================] - 0s 867us/step - loss: 22.7560\n",
            "Epoch 355/1000\n",
            "16/16 [==============================] - 0s 675us/step - loss: 23.7639\n",
            "Epoch 356/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3092\n",
            "Epoch 357/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.1255\n",
            "Epoch 358/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8321\n",
            "Epoch 359/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9811\n",
            "Epoch 360/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.9448\n",
            "Epoch 361/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1428\n",
            "Epoch 362/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9995\n",
            "Epoch 363/1000\n",
            "16/16 [==============================] - 0s 468us/step - loss: 22.6040\n",
            "Epoch 364/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.1583\n",
            "Epoch 365/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0218\n",
            "Epoch 366/1000\n",
            "16/16 [==============================] - 0s 468us/step - loss: 22.6912\n",
            "Epoch 367/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1405\n",
            "Epoch 368/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9788\n",
            "Epoch 369/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9474\n",
            "Epoch 370/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8886\n",
            "Epoch 371/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1592\n",
            "Epoch 372/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9571\n",
            "Epoch 373/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1563\n",
            "Epoch 374/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2652\n",
            "Epoch 375/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8838\n",
            "Epoch 376/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3966\n",
            "Epoch 377/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1225\n",
            "Epoch 378/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0934\n",
            "Epoch 379/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2672\n",
            "Epoch 380/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8582\n",
            "Epoch 381/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.0631\n",
            "Epoch 382/1000\n",
            "16/16 [==============================] - 0s 734us/step - loss: 23.1260\n",
            "Epoch 383/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8223\n",
            "Epoch 384/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1277\n",
            "Epoch 385/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2571\n",
            "Epoch 386/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3477\n",
            "Epoch 387/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8475\n",
            "Epoch 388/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0822\n",
            "Epoch 389/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.7503\n",
            "Epoch 390/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9889\n",
            "Epoch 391/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8292\n",
            "Epoch 392/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9905\n",
            "Epoch 393/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4609\n",
            "Epoch 394/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0326\n",
            "Epoch 395/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8077\n",
            "Epoch 396/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.1041\n",
            "Epoch 397/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7902\n",
            "Epoch 398/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8884\n",
            "Epoch 399/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0641\n",
            "Epoch 400/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8558\n",
            "Epoch 401/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9286\n",
            "Epoch 402/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6455\n",
            "Epoch 403/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9435\n",
            "Epoch 404/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0824\n",
            "Epoch 405/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1171\n",
            "Epoch 406/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.8136\n",
            "Epoch 407/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8008\n",
            "Epoch 408/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2356\n",
            "Epoch 409/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.1332\n",
            "Epoch 410/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8257\n",
            "Epoch 411/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.1034\n",
            "Epoch 412/1000\n",
            "16/16 [==============================] - 0s 933us/step - loss: 22.8623\n",
            "Epoch 413/1000\n",
            "16/16 [==============================] - 0s 933us/step - loss: 23.2487\n",
            "Epoch 414/1000\n",
            "16/16 [==============================] - 0s 734us/step - loss: 22.9529\n",
            "Epoch 415/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4121\n",
            "Epoch 416/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8794\n",
            "Epoch 417/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4928\n",
            "Epoch 418/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0375\n",
            "Epoch 419/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4003\n",
            "Epoch 420/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0264\n",
            "Epoch 421/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2157\n",
            "Epoch 422/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2553\n",
            "Epoch 423/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.6740\n",
            "Epoch 424/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.7393\n",
            "Epoch 425/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9537\n",
            "Epoch 426/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.5702\n",
            "Epoch 427/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0700\n",
            "Epoch 428/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1735\n",
            "Epoch 429/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9686\n",
            "Epoch 430/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7523\n",
            "Epoch 431/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8708\n",
            "Epoch 432/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2436\n",
            "Epoch 433/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0900\n",
            "Epoch 434/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3326\n",
            "Epoch 435/1000\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.0291\n",
            "Epoch 436/1000\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.3067\n",
            "Epoch 437/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.7308\n",
            "Epoch 438/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8987\n",
            "Epoch 439/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 22.6875\n",
            "Epoch 440/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8471\n",
            "Epoch 441/1000\n",
            "16/16 [==============================] - 0s 734us/step - loss: 23.4895\n",
            "Epoch 442/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.2441\n",
            "Epoch 443/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 12.79 - 0s 800us/step - loss: 22.6843\n",
            "Epoch 444/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1733\n",
            "Epoch 445/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.5060\n",
            "Epoch 446/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8922\n",
            "Epoch 447/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.3861\n",
            "Epoch 448/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.6598\n",
            "Epoch 449/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8960\n",
            "Epoch 450/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8460\n",
            "Epoch 451/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8900\n",
            "Epoch 452/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7656\n",
            "Epoch 453/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9870\n",
            "Epoch 454/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2442\n",
            "Epoch 455/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8516\n",
            "Epoch 456/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8894\n",
            "Epoch 457/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2024\n",
            "Epoch 458/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9136\n",
            "Epoch 459/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1979\n",
            "Epoch 460/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0031\n",
            "Epoch 461/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2625\n",
            "Epoch 462/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0220\n",
            "Epoch 463/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0952\n",
            "Epoch 464/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9627\n",
            "Epoch 465/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3861\n",
            "Epoch 466/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8885\n",
            "Epoch 467/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1199\n",
            "Epoch 468/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7706\n",
            "Epoch 469/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4893\n",
            "Epoch 470/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3719\n",
            "Epoch 471/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9200\n",
            "Epoch 472/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9707\n",
            "Epoch 473/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7585\n",
            "Epoch 474/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8973\n",
            "Epoch 475/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.6129\n",
            "Epoch 476/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1119\n",
            "Epoch 477/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1167\n",
            "Epoch 478/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8870\n",
            "Epoch 479/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4409\n",
            "Epoch 480/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.6101\n",
            "Epoch 481/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9910\n",
            "Epoch 482/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.6944\n",
            "Epoch 483/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0518\n",
            "Epoch 484/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3253\n",
            "Epoch 485/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1309\n",
            "Epoch 486/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7119\n",
            "Epoch 487/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4997\n",
            "Epoch 488/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.7144\n",
            "Epoch 489/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0955\n",
            "Epoch 490/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4384\n",
            "Epoch 491/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3755\n",
            "Epoch 492/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8524\n",
            "Epoch 493/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4592\n",
            "Epoch 494/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.2714\n",
            "Epoch 495/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4511\n",
            "Epoch 496/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7976\n",
            "Epoch 497/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1969\n",
            "Epoch 498/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9977\n",
            "Epoch 499/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8547\n",
            "Epoch 500/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8566\n",
            "Epoch 501/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8013\n",
            "Epoch 502/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1748\n",
            "Epoch 503/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1587\n",
            "Epoch 504/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.4905\n",
            "Epoch 505/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9175\n",
            "Epoch 506/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8339\n",
            "Epoch 507/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0912\n",
            "Epoch 508/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8451\n",
            "Epoch 509/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3125\n",
            "Epoch 510/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7848\n",
            "Epoch 511/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6284\n",
            "Epoch 512/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2693\n",
            "Epoch 513/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0502\n",
            "Epoch 514/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0002\n",
            "Epoch 515/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0109\n",
            "Epoch 516/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9206\n",
            "Epoch 517/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6462\n",
            "Epoch 518/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.5352\n",
            "Epoch 519/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1279\n",
            "Epoch 520/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4012\n",
            "Epoch 521/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8536\n",
            "Epoch 522/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2143\n",
            "Epoch 523/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8334\n",
            "Epoch 524/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9728\n",
            "Epoch 525/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0557\n",
            "Epoch 526/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6360\n",
            "Epoch 527/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3507\n",
            "Epoch 528/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1988\n",
            "Epoch 529/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8496\n",
            "Epoch 530/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2630\n",
            "Epoch 531/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0793\n",
            "Epoch 532/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9981\n",
            "Epoch 533/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.4057\n",
            "Epoch 534/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9725\n",
            "Epoch 535/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8886\n",
            "Epoch 536/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8032\n",
            "Epoch 537/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0404\n",
            "Epoch 538/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1971\n",
            "Epoch 539/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0702\n",
            "Epoch 540/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0950\n",
            "Epoch 541/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9882\n",
            "Epoch 542/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8402\n",
            "Epoch 543/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1150\n",
            "Epoch 544/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2137\n",
            "Epoch 545/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.5086\n",
            "Epoch 546/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9959\n",
            "Epoch 547/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9676\n",
            "Epoch 548/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3793\n",
            "Epoch 549/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1836\n",
            "Epoch 550/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7649\n",
            "Epoch 551/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9859\n",
            "Epoch 552/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7907\n",
            "Epoch 553/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9674\n",
            "Epoch 554/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.7788\n",
            "Epoch 555/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.9075\n",
            "Epoch 556/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7873\n",
            "Epoch 557/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3609\n",
            "Epoch 558/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6875\n",
            "Epoch 559/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.3080\n",
            "Epoch 560/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0335\n",
            "Epoch 561/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.4775\n",
            "Epoch 562/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1430\n",
            "Epoch 563/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1061\n",
            "Epoch 564/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1925\n",
            "Epoch 565/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0822\n",
            "Epoch 566/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6635\n",
            "Epoch 567/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7600\n",
            "Epoch 568/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2528\n",
            "Epoch 569/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2078\n",
            "Epoch 570/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7784\n",
            "Epoch 571/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2218\n",
            "Epoch 572/1000\n",
            "16/16 [==============================] - 0s 601us/step - loss: 22.9618\n",
            "Epoch 573/1000\n",
            "16/16 [==============================] - 0s 333us/step - loss: 23.2303\n",
            "Epoch 574/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.7395\n",
            "Epoch 575/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1297\n",
            "Epoch 576/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0067\n",
            "Epoch 577/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4539\n",
            "Epoch 578/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2904\n",
            "Epoch 579/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.6956\n",
            "Epoch 580/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1117\n",
            "Epoch 581/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4775\n",
            "Epoch 582/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3894\n",
            "Epoch 583/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2972\n",
            "Epoch 584/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.8118\n",
            "Epoch 585/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8462\n",
            "Epoch 586/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0660\n",
            "Epoch 587/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0194\n",
            "Epoch 588/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0179\n",
            "Epoch 589/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0979\n",
            "Epoch 590/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7754\n",
            "Epoch 591/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9523\n",
            "Epoch 592/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 42.22 - 0s 400us/step - loss: 23.3446\n",
            "Epoch 593/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1569\n",
            "Epoch 594/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0845\n",
            "Epoch 595/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9545\n",
            "Epoch 596/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3573\n",
            "Epoch 597/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.7580\n",
            "Epoch 598/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0955\n",
            "Epoch 599/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9385\n",
            "Epoch 600/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1074\n",
            "Epoch 601/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.7091\n",
            "Epoch 602/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2805\n",
            "Epoch 603/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8427\n",
            "Epoch 604/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9491\n",
            "Epoch 605/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4118\n",
            "Epoch 606/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8492\n",
            "Epoch 607/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0115\n",
            "Epoch 608/1000\n",
            "16/16 [==============================] - 0s 599us/step - loss: 23.1586\n",
            "Epoch 609/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7536\n",
            "Epoch 610/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9323\n",
            "Epoch 611/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8275\n",
            "Epoch 612/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3019\n",
            "Epoch 613/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0047\n",
            "Epoch 614/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1921\n",
            "Epoch 615/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2310\n",
            "Epoch 616/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8507\n",
            "Epoch 617/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9369\n",
            "Epoch 618/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1711\n",
            "Epoch 619/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2559\n",
            "Epoch 620/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2042\n",
            "Epoch 621/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1318\n",
            "Epoch 622/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1666\n",
            "Epoch 623/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8151\n",
            "Epoch 624/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1113\n",
            "Epoch 625/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9307\n",
            "Epoch 626/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8861\n",
            "Epoch 627/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4710\n",
            "Epoch 628/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9994\n",
            "Epoch 629/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4130\n",
            "Epoch 630/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1230\n",
            "Epoch 631/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2912\n",
            "Epoch 632/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3966\n",
            "Epoch 633/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.5513\n",
            "Epoch 634/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.0790\n",
            "Epoch 635/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9029\n",
            "Epoch 636/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0294\n",
            "Epoch 637/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9934\n",
            "Epoch 638/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1230\n",
            "Epoch 639/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0747\n",
            "Epoch 640/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1736\n",
            "Epoch 641/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9415\n",
            "Epoch 642/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0490\n",
            "Epoch 643/1000\n",
            "16/16 [==============================] - 0s 468us/step - loss: 23.0473\n",
            "Epoch 644/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6818\n",
            "Epoch 645/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.6532\n",
            "Epoch 646/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0530\n",
            "Epoch 647/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3671\n",
            "Epoch 648/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0046\n",
            "Epoch 649/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9806\n",
            "Epoch 650/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.4769\n",
            "Epoch 651/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9603\n",
            "Epoch 652/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1444\n",
            "Epoch 653/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0826\n",
            "Epoch 654/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0419\n",
            "Epoch 655/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1245\n",
            "Epoch 656/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8188\n",
            "Epoch 657/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1270\n",
            "Epoch 658/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2660\n",
            "Epoch 659/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3000\n",
            "Epoch 660/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1864\n",
            "Epoch 661/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6137\n",
            "Epoch 662/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.5196\n",
            "Epoch 663/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0725\n",
            "Epoch 664/1000\n",
            "16/16 [==============================] - 0s 401us/step - loss: 23.0114\n",
            "Epoch 665/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8305\n",
            "Epoch 666/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8608\n",
            "Epoch 667/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.2735\n",
            "Epoch 668/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2984\n",
            "Epoch 669/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1699\n",
            "Epoch 670/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7417\n",
            "Epoch 671/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2589\n",
            "Epoch 672/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0301\n",
            "Epoch 673/1000\n",
            "16/16 [==============================] - 0s 666us/step - loss: 23.1686\n",
            "Epoch 674/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9079\n",
            "Epoch 675/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1002\n",
            "Epoch 676/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1370\n",
            "Epoch 677/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.4478\n",
            "Epoch 678/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3202\n",
            "Epoch 679/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0179\n",
            "Epoch 680/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3706\n",
            "Epoch 681/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3034\n",
            "Epoch 682/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1082\n",
            "Epoch 683/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8764\n",
            "Epoch 684/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0823\n",
            "Epoch 685/1000\n",
            "16/16 [==============================] - 0s 601us/step - loss: 22.9083\n",
            "Epoch 686/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1654\n",
            "Epoch 687/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0407\n",
            "Epoch 688/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1287\n",
            "Epoch 689/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7695\n",
            "Epoch 690/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0467\n",
            "Epoch 691/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8154\n",
            "Epoch 692/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1406\n",
            "Epoch 693/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9327\n",
            "Epoch 694/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1239\n",
            "Epoch 695/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7493\n",
            "Epoch 696/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9930\n",
            "Epoch 697/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9466\n",
            "Epoch 698/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0483\n",
            "Epoch 699/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9500\n",
            "Epoch 700/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0833\n",
            "Epoch 701/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1460\n",
            "Epoch 702/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3391\n",
            "Epoch 703/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8702\n",
            "Epoch 704/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.5055\n",
            "Epoch 705/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1676\n",
            "Epoch 706/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2950\n",
            "Epoch 707/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1624\n",
            "Epoch 708/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3195\n",
            "Epoch 709/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2739\n",
            "Epoch 710/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2769\n",
            "Epoch 711/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8934\n",
            "Epoch 712/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4747\n",
            "Epoch 713/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8833\n",
            "Epoch 714/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.4152\n",
            "Epoch 715/1000\n",
            "16/16 [==============================] - 0s 534us/step - loss: 23.2403\n",
            "Epoch 716/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6870\n",
            "Epoch 717/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0999\n",
            "Epoch 718/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1557\n",
            "Epoch 719/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3424\n",
            "Epoch 720/1000\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.0416\n",
            "Epoch 721/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4159\n",
            "Epoch 722/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9757\n",
            "Epoch 723/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9532\n",
            "Epoch 724/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1377\n",
            "Epoch 725/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7544\n",
            "Epoch 726/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9607\n",
            "Epoch 727/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1934\n",
            "Epoch 728/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.4207\n",
            "Epoch 729/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1020\n",
            "Epoch 730/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1686\n",
            "Epoch 731/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0541\n",
            "Epoch 732/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3112\n",
            "Epoch 733/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0557\n",
            "Epoch 734/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3100\n",
            "Epoch 735/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6322\n",
            "Epoch 736/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.7637\n",
            "Epoch 737/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0815\n",
            "Epoch 738/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2154\n",
            "Epoch 739/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9226\n",
            "Epoch 740/1000\n",
            "16/16 [==============================] - 0s 500us/step - loss: 23.4229\n",
            "Epoch 741/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1663\n",
            "Epoch 742/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1710\n",
            "Epoch 743/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.4513\n",
            "Epoch 744/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8774\n",
            "Epoch 745/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.5157\n",
            "Epoch 746/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1755\n",
            "Epoch 747/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0033\n",
            "Epoch 748/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.5450\n",
            "Epoch 749/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.3281\n",
            "Epoch 750/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1980\n",
            "Epoch 751/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4245\n",
            "Epoch 752/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0700\n",
            "Epoch 753/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.4986\n",
            "Epoch 754/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1263\n",
            "Epoch 755/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8687\n",
            "Epoch 756/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2201\n",
            "Epoch 757/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.7318\n",
            "Epoch 758/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9205\n",
            "Epoch 759/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9182\n",
            "Epoch 760/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2462\n",
            "Epoch 761/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1430\n",
            "Epoch 762/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1834\n",
            "Epoch 763/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.7648\n",
            "Epoch 764/1000\n",
            "16/16 [==============================] - 0s 666us/step - loss: 23.1280\n",
            "Epoch 765/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3313\n",
            "Epoch 766/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1204\n",
            "Epoch 767/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.5081\n",
            "Epoch 768/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4042\n",
            "Epoch 769/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.6476\n",
            "Epoch 770/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9580\n",
            "Epoch 771/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2169\n",
            "Epoch 772/1000\n",
            "16/16 [==============================] - 0s 867us/step - loss: 22.9097\n",
            "Epoch 773/1000\n",
            "16/16 [==============================] - 0s 816us/step - loss: 23.2532\n",
            "Epoch 774/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.3384\n",
            "Epoch 775/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8586\n",
            "Epoch 776/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1851\n",
            "Epoch 777/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0150\n",
            "Epoch 778/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3299\n",
            "Epoch 779/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8955\n",
            "Epoch 780/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.2860\n",
            "Epoch 781/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.0567\n",
            "Epoch 782/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9644\n",
            "Epoch 783/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4860\n",
            "Epoch 784/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.8306\n",
            "Epoch 785/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.1607\n",
            "Epoch 786/1000\n",
            "16/16 [==============================] - 0s 867us/step - loss: 23.0678\n",
            "Epoch 787/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3005\n",
            "Epoch 788/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1064\n",
            "Epoch 789/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.2370\n",
            "Epoch 790/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 22.8097\n",
            "Epoch 791/1000\n",
            "16/16 [==============================] - 0s 734us/step - loss: 23.2229\n",
            "Epoch 792/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.0469\n",
            "Epoch 793/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.2123\n",
            "Epoch 794/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 22.9591\n",
            "Epoch 795/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0021\n",
            "Epoch 796/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2997\n",
            "Epoch 797/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0848\n",
            "Epoch 798/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2057\n",
            "Epoch 799/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4363\n",
            "Epoch 800/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7430\n",
            "Epoch 801/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.5331\n",
            "Epoch 802/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.5458\n",
            "Epoch 803/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0553\n",
            "Epoch 804/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3190\n",
            "Epoch 805/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2323\n",
            "Epoch 806/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2744\n",
            "Epoch 807/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2871\n",
            "Epoch 808/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3862\n",
            "Epoch 809/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1104\n",
            "Epoch 810/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4153\n",
            "Epoch 811/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4153\n",
            "Epoch 812/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1802\n",
            "Epoch 813/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9912\n",
            "Epoch 814/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3964\n",
            "Epoch 815/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9540\n",
            "Epoch 816/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0644\n",
            "Epoch 817/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0622\n",
            "Epoch 818/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0846\n",
            "Epoch 819/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0914\n",
            "Epoch 820/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3027\n",
            "Epoch 821/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.6679\n",
            "Epoch 822/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3933\n",
            "Epoch 823/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2439\n",
            "Epoch 824/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1733\n",
            "Epoch 825/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.8827\n",
            "Epoch 826/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9225\n",
            "Epoch 827/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0562\n",
            "Epoch 828/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4062\n",
            "Epoch 829/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7733\n",
            "Epoch 830/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0263\n",
            "Epoch 831/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2005\n",
            "Epoch 832/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8949\n",
            "Epoch 833/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0227\n",
            "Epoch 834/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 22.7084\n",
            "Epoch 835/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7161\n",
            "Epoch 836/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.8121\n",
            "Epoch 837/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.2014\n",
            "Epoch 838/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9245\n",
            "Epoch 839/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 15.20 - 0s 933us/step - loss: 22.7950\n",
            "Epoch 840/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0066\n",
            "Epoch 841/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7130\n",
            "Epoch 842/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1304\n",
            "Epoch 843/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9261\n",
            "Epoch 844/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2222\n",
            "Epoch 845/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0450\n",
            "Epoch 846/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9064\n",
            "Epoch 847/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0230\n",
            "Epoch 848/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0166\n",
            "Epoch 849/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0053\n",
            "Epoch 850/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1764\n",
            "Epoch 851/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9425\n",
            "Epoch 852/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8873\n",
            "Epoch 853/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0936\n",
            "Epoch 854/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1031\n",
            "Epoch 855/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3781\n",
            "Epoch 856/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8304\n",
            "Epoch 857/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3534\n",
            "Epoch 858/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9915\n",
            "Epoch 859/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7571\n",
            "Epoch 860/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2556\n",
            "Epoch 861/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.7767\n",
            "Epoch 862/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2515\n",
            "Epoch 863/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.8402\n",
            "Epoch 864/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.1272\n",
            "Epoch 865/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.4212\n",
            "Epoch 866/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1928\n",
            "Epoch 867/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3548\n",
            "Epoch 868/1000\n",
            "16/16 [==============================] - 0s 623us/step - loss: 22.9239\n",
            "Epoch 869/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8521\n",
            "Epoch 870/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2575\n",
            "Epoch 871/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.7702\n",
            "Epoch 872/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2231\n",
            "Epoch 873/1000\n",
            "16/16 [==============================] - 0s 535us/step - loss: 23.1087\n",
            "Epoch 874/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8886\n",
            "Epoch 875/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.0535\n",
            "Epoch 876/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1217\n",
            "Epoch 877/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1542\n",
            "Epoch 878/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1897\n",
            "Epoch 879/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9491\n",
            "Epoch 880/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2817\n",
            "Epoch 881/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1164\n",
            "Epoch 882/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0547\n",
            "Epoch 883/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2042\n",
            "Epoch 884/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9011\n",
            "Epoch 885/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9037\n",
            "Epoch 886/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.4620\n",
            "Epoch 887/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1668\n",
            "Epoch 888/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1972\n",
            "Epoch 889/1000\n",
            "16/16 [==============================] - 0s 867us/step - loss: 22.8232\n",
            "Epoch 890/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.1106\n",
            "Epoch 891/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.2295\n",
            "Epoch 892/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0066\n",
            "Epoch 893/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.5456\n",
            "Epoch 894/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.6710\n",
            "Epoch 895/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.7826\n",
            "Epoch 896/1000\n",
            "16/16 [==============================] - 0s 764us/step - loss: 22.9133\n",
            "Epoch 897/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.4200\n",
            "Epoch 898/1000\n",
            "16/16 [==============================] - 0s 933us/step - loss: 22.8269\n",
            "Epoch 899/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9778\n",
            "Epoch 900/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9631\n",
            "Epoch 901/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.5736\n",
            "Epoch 902/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2058\n",
            "Epoch 903/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.4969\n",
            "Epoch 904/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3091\n",
            "Epoch 905/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3760\n",
            "Epoch 906/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6452\n",
            "Epoch 907/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8714\n",
            "Epoch 908/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9016\n",
            "Epoch 909/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9995\n",
            "Epoch 910/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3476\n",
            "Epoch 911/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9195\n",
            "Epoch 912/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9769\n",
            "Epoch 913/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.8091\n",
            "Epoch 914/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1622\n",
            "Epoch 915/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3193\n",
            "Epoch 916/1000\n",
            "16/16 [==============================] - 0s 534us/step - loss: 22.8551\n",
            "Epoch 917/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.5631\n",
            "Epoch 918/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 23.3068\n",
            "Epoch 919/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7134\n",
            "Epoch 920/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9410\n",
            "Epoch 921/1000\n",
            "16/16 [==============================] - 0s 534us/step - loss: 22.7081\n",
            "Epoch 922/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.4389\n",
            "Epoch 923/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9090\n",
            "Epoch 924/1000\n",
            "16/16 [==============================] - 0s 800us/step - loss: 23.1881\n",
            "Epoch 925/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.1787\n",
            "Epoch 926/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.8212\n",
            "Epoch 927/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.5362\n",
            "Epoch 928/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9688\n",
            "Epoch 929/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9614\n",
            "Epoch 930/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9662\n",
            "Epoch 931/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.7649\n",
            "Epoch 932/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 23.2880\n",
            "Epoch 933/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.5329\n",
            "Epoch 934/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8235\n",
            "Epoch 935/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.1943\n",
            "Epoch 936/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.6697\n",
            "Epoch 937/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9902\n",
            "Epoch 938/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0262\n",
            "Epoch 939/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8722\n",
            "Epoch 940/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.2741\n",
            "Epoch 941/1000\n",
            "16/16 [==============================] - 0s 668us/step - loss: 23.4611\n",
            "Epoch 942/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.9199\n",
            "Epoch 943/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3841\n",
            "Epoch 944/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.6422\n",
            "Epoch 945/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.6309\n",
            "Epoch 946/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9816\n",
            "Epoch 947/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9180\n",
            "Epoch 948/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.9637\n",
            "Epoch 949/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.7062\n",
            "Epoch 950/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0362\n",
            "Epoch 951/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.3091\n",
            "Epoch 952/1000\n",
            "16/16 [==============================] - 0s 944us/step - loss: 22.9068\n",
            "Epoch 953/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.0432\n",
            "Epoch 954/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2231\n",
            "Epoch 955/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.7087\n",
            "Epoch 956/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.2137\n",
            "Epoch 957/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.7532\n",
            "Epoch 958/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2384\n",
            "Epoch 959/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9882\n",
            "Epoch 960/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0407\n",
            "Epoch 961/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9838\n",
            "Epoch 962/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7373\n",
            "Epoch 963/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6937\n",
            "Epoch 964/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3492\n",
            "Epoch 965/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2063\n",
            "Epoch 966/1000\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 22.6320\n",
            "Epoch 967/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 23.0797\n",
            "Epoch 968/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.0907\n",
            "Epoch 969/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.4023\n",
            "Epoch 970/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.6100\n",
            "Epoch 971/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.5116\n",
            "Epoch 972/1000\n",
            "16/16 [==============================] - 0s 465us/step - loss: 23.0480\n",
            "Epoch 973/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.8932\n",
            "Epoch 974/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2943\n",
            "Epoch 975/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2090\n",
            "Epoch 976/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.0044\n",
            "Epoch 977/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 22.9278\n",
            "Epoch 978/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.2050\n",
            "Epoch 979/1000\n",
            "16/16 [==============================] - 0s 466us/step - loss: 22.9516\n",
            "Epoch 980/1000\n",
            "16/16 [==============================] - 0s 600us/step - loss: 23.3261\n",
            "Epoch 981/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0829\n",
            "Epoch 982/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.9539\n",
            "Epoch 983/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.1616\n",
            "Epoch 984/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0833\n",
            "Epoch 985/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3111\n",
            "Epoch 986/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.6409\n",
            "Epoch 987/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3556\n",
            "Epoch 988/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 22.7976\n",
            "Epoch 989/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 23.3679\n",
            "Epoch 990/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.0042\n",
            "Epoch 991/1000\n",
            "16/16 [==============================] - 0s 533us/step - loss: 22.3758\n",
            "Epoch 992/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.3335\n",
            "Epoch 993/1000\n",
            "16/16 [==============================] - 0s 733us/step - loss: 22.9657\n",
            "Epoch 994/1000\n",
            "16/16 [==============================] - 0s 666us/step - loss: 23.2508\n",
            "Epoch 995/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 22.9751\n",
            "Epoch 996/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.7858\n",
            "Epoch 997/1000\n",
            "16/16 [==============================] - 0s 601us/step - loss: 22.8891\n",
            "Epoch 998/1000\n",
            "16/16 [==============================] - 0s 400us/step - loss: 23.2220\n",
            "Epoch 999/1000\n",
            "16/16 [==============================] - 0s 667us/step - loss: 22.9938\n",
            "Epoch 1000/1000\n",
            "16/16 [==============================] - 0s 467us/step - loss: 23.2106\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1f0ff9eb160>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 fit 하기\n",
        "model_bos.fit(ind_var_boston, dep_var_boston,epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "another-defensive",
      "metadata": {
        "id": "another-defensive",
        "outputId": "aa08b868-614f-44cd-8385-28f4324e3a31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[29.205477],\n",
              "       [24.21123 ],\n",
              "       [30.376736],\n",
              "       [28.764305],\n",
              "       [28.282923]], dtype=float32)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_bos.predict(ind_var_boston[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unable-lotus",
      "metadata": {
        "id": "unable-lotus",
        "outputId": "e1ee2b85-8100-4d6c-9bea-6532c97ba56c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   medv\n",
              "0  24.0\n",
              "1  21.6\n",
              "2  34.7\n",
              "3  33.4\n",
              "4  36.2"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boston[['medv']][0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nutritional-relaxation",
      "metadata": {
        "id": "nutritional-relaxation",
        "outputId": "ddbd0eb2-6adc-4b0c-f313-d7bfa11b32e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-9.7691655e-02],\n",
              "        [ 4.6617780e-02],\n",
              "        [-3.6868413e-03],\n",
              "        [ 2.6346443e+00],\n",
              "        [-8.5219727e+00],\n",
              "        [ 4.7443485e+00],\n",
              "        [-6.1575826e-03],\n",
              "        [-1.2278856e+00],\n",
              "        [ 2.3755276e-01],\n",
              "        [-1.2053286e-02],\n",
              "        [-6.8141276e-01],\n",
              "        [ 1.1240847e-02],\n",
              "        [-4.8472962e-01]], dtype=float32),\n",
              " array([18.898045], dtype=float32)]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 수식 확인\n",
        "model_bos.get_weights()  # 가중치 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "returning-harvey",
      "metadata": {
        "id": "returning-harvey"
      },
      "outputs": [],
      "source": [
        "# arr = model_bos.get_weights()\n",
        "# weight = arr[0]\n",
        "# weight = weight.tolist()\n",
        "# weight = sum(weight,[])\n",
        "\n",
        "# res = 0\n",
        "\n",
        "# for i in weight:\n",
        "# #     res+=i\n",
        "#     print(i)\n",
        "# print(weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "alpha-south",
      "metadata": {
        "id": "alpha-south"
      },
      "source": [
        "# Iris classification\n",
        "## 품종을 종속 변수로 지정하는데, 위에서와는 달리 수치형 변수가 아닌 범주형 변수이기 때문에 회귀 알고리즘이 아닌, 분류 알고리즘을 사용해야한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial-ribbon",
      "metadata": {
        "id": "initial-ribbon",
        "outputId": "68356354-bf9a-457f-8ff5-0ee0a9e59f3c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭         품종\n",
              "0     5.1  3.5    1.4   0.2     setosa\n",
              "1     4.9  3.0    1.4   0.2     setosa\n",
              "2     4.7  3.2    1.3   0.2     setosa\n",
              "3     4.6  3.1    1.5   0.2     setosa\n",
              "4     5.0  3.6    1.4   0.2     setosa\n",
              "..    ...  ...    ...   ...        ...\n",
              "145   6.7  3.0    5.2   2.3  virginica\n",
              "146   6.3  2.5    5.0   1.9  virginica\n",
              "147   6.5  3.0    5.2   2.0  virginica\n",
              "148   6.2  3.4    5.4   2.3  virginica\n",
              "149   5.9  3.0    5.1   1.8  virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris\n",
        "# 꽃잎 -> petal, 꽃받침 -> sepal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tracked-material",
      "metadata": {
        "id": "tracked-material"
      },
      "source": [
        "# Onehot-encoding\n",
        "## 딥러닝 모델을 사용하기 위해서는 모든 범주형 변수를 Onehot-encoding 해줘야함.\n",
        "### -> pd.get_dummies 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olympic-impression",
      "metadata": {
        "id": "olympic-impression"
      },
      "outputs": [],
      "source": [
        "# Onehot-encoding\n",
        "# get_dummies를 사용하면 데이터 내의 범주형 변수들만 골라서 원핫인코딩 된 결과 만들어줌\n",
        "iris = pd.get_dummies(iris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "august-plaza",
      "metadata": {
        "id": "august-plaza",
        "outputId": "11ac4c61-ebd1-4841-cb5e-da79d603eca7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종_setosa</th>\n",
              "      <th>품종_versicolor</th>\n",
              "      <th>품종_virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭  품종_setosa  품종_versicolor  품종_virginica\n",
              "0     5.1  3.5    1.4   0.2          1              0             0\n",
              "1     4.9  3.0    1.4   0.2          1              0             0\n",
              "2     4.7  3.2    1.3   0.2          1              0             0\n",
              "3     4.6  3.1    1.5   0.2          1              0             0\n",
              "4     5.0  3.6    1.4   0.2          1              0             0\n",
              "..    ...  ...    ...   ...        ...            ...           ...\n",
              "145   6.7  3.0    5.2   2.3          0              0             1\n",
              "146   6.3  2.5    5.0   1.9          0              0             1\n",
              "147   6.5  3.0    5.2   2.0          0              0             1\n",
              "148   6.2  3.4    5.4   2.3          0              0             1\n",
              "149   5.9  3.0    5.1   1.8          0              0             1\n",
              "\n",
              "[150 rows x 7 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "informative-undergraduate",
      "metadata": {
        "id": "informative-undergraduate"
      },
      "source": [
        "# setosa, versicolor, virginica 세 가지 품종에 대한 수식을 만들어야함\n",
        "# y1 = w1x1+w2x2+.... + b -> setosa\n",
        "# y2 = w1x1 + ... + b -> versicolor\n",
        "# y3 = w1x1 + ... + b -> virginica\n",
        "\n",
        "## 따라서, 컴퓨터는 세 가지 품종에 대한 가중치를 모두 찾아야함"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "temporal-methodology",
      "metadata": {
        "id": "temporal-methodology"
      },
      "source": [
        "# Softmax\n",
        "## 비율 예측을 위해 activation function 중 하나인 Softmax 사용\n",
        "## activation function 역할: 퍼셉트론의 출력이 어떤 형태로 나가야하는지를 조절해줌\n",
        "\n",
        "## 회귀에 사용하게 되는 loss는 mse, 분류에 사용하는 loss는 categorical_crossentropy이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hourly-resident",
      "metadata": {
        "id": "hourly-resident",
        "outputId": "3fba65e3-bd02-4211-9d07-0fd276ce9ee5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n",
              "       '품종_virginica'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "personalized-pricing",
      "metadata": {
        "id": "personalized-pricing"
      },
      "outputs": [],
      "source": [
        "ind_var_iris = iris[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "dep_var_iris = iris[['품종_setosa', '품종_versicolor',\n",
        "       '품종_virginica']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worth-ranch",
      "metadata": {
        "id": "worth-ranch"
      },
      "outputs": [],
      "source": [
        "X = tf.keras.layers.Input(shape=[4])\n",
        "Y = tf.keras.layers.Dense(3,activation='softmax')(X)\n",
        "model_iris = tf.keras.models.Model(X,Y)\n",
        "model_iris.compile(loss = 'categorical_crossentropy',metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shared-david",
      "metadata": {
        "id": "shared-david",
        "outputId": "6bc1a199-28ed-4dfb-92aa-48dc7ab374ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8456 - accuracy: 0.4867\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8401 - accuracy: 0.4800\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8343 - accuracy: 0.4867\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8302 - accuracy: 0.5067\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8247 - accuracy: 0.5133\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.8192 - accuracy: 0.4933\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8140 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.8087 - accuracy: 0.5067\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8045 - accuracy: 0.5133\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7984 - accuracy: 0.5067\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7942 - accuracy: 0.5133\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.5067\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7853 - accuracy: 0.5267\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7809 - accuracy: 0.5133\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.5200\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7718 - accuracy: 0.5200\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7684 - accuracy: 0.5200\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7648 - accuracy: 0.5333\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7607 - accuracy: 0.5067\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7582 - accuracy: 0.5200\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.7530 - accuracy: 0.5067\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.5333\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.7458 - accuracy: 0.5267\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.5467\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.5400\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.7313 - accuracy: 0.5200\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.5267\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.7231 - accuracy: 0.5267\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.7194 - accuracy: 0.5400\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.7157 - accuracy: 0.5467\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.5267\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.5333\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.7055 - accuracy: 0.5400\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.7027 - accuracy: 0.5667\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5667\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.6959 - accuracy: 0.5333\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5800\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5533\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.6871 - accuracy: 0.5733\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5600\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5667\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5467\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.5733\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5867\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.5800\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.6656 - accuracy: 0.5800\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5667\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6067\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.5867\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6000\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6067\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.5600\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.5800\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.6267\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.6392 - accuracy: 0.6000\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.6368 - accuracy: 0.6067\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.6345 - accuracy: 0.5933\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6067\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.6295 - accuracy: 0.5867\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.6257 - accuracy: 0.6200\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.6237 - accuracy: 0.6067\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6133\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.6333\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6400\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.6200\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6267\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.6533\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6533\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.6467\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6467\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6600\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6600\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5975 - accuracy: 0.6400\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.6467\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.6600\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.5903 - accuracy: 0.6467\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 500us/step - loss: 0.5893 - accuracy: 0.6333\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6600\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6600\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6733\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5764 - accuracy: 0.6733\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.6733\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6733\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5710 - accuracy: 0.6733\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5706 - accuracy: 0.6867\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5672 - accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.6933\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5635 - accuracy: 0.6867\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5618 - accuracy: 0.6933\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.6867\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5585 - accuracy: 0.6933\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.6800\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7067\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.7067\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.5495 - accuracy: 0.7133\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1f0ffda6160>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_iris.fit(ind_var_iris, dep_var_iris,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "naval-november",
      "metadata": {
        "id": "naval-november",
        "outputId": "f71b846b-4e5d-4283-b203-053b5f255b70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.8712439 , 0.08247293, 0.04628321],\n",
              "       [0.7988932 , 0.12082543, 0.08028137],\n",
              "       [0.84736276, 0.09864279, 0.05399444],\n",
              "       [0.8014828 , 0.1275649 , 0.07095232],\n",
              "       [0.88317704, 0.07734422, 0.03947882]], dtype=float32)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 처음에 있는 5개의 데이터를 가지고 예측\n",
        "model_iris.predict(ind_var_iris[0:5])\n",
        "# 퍼센티지가 가장 높은 쪽으로 꽃 종류 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "serial-water",
      "metadata": {
        "id": "serial-water",
        "outputId": "ec5190f0-8881-4b20-c8bc-69e1628d6c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   품종_setosa  품종_versicolor  품종_virginica\n",
            "0          1              0             0\n",
            "1          1              0             0\n",
            "2          1              0             0\n",
            "3          1              0             0\n",
            "4          1              0             0\n"
          ]
        }
      ],
      "source": [
        "print(dep_var_iris[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brief-equality",
      "metadata": {
        "id": "brief-equality",
        "outputId": "be0d18f9-ab56-4c60-cd2b-6f69d93d12c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0316449 , 0.43595567, 0.5323994 ],\n",
              "       [0.0253917 , 0.40595078, 0.5686575 ],\n",
              "       [0.03473356, 0.44396582, 0.5213007 ],\n",
              "       [0.04200952, 0.5301942 , 0.42779627],\n",
              "       [0.04301732, 0.49600676, 0.46097597]], dtype=float32)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 끝에 있는 5개 예측\n",
        "model_iris.predict(ind_var_iris[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accessory-assets",
      "metadata": {
        "id": "accessory-assets",
        "outputId": "97b47d6e-df33-4221-ec2d-22cf19e6e44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     품종_setosa  품종_versicolor  품종_virginica\n",
            "145          0              0             1\n",
            "146          0              0             1\n",
            "147          0              0             1\n",
            "148          0              0             1\n",
            "149          0              0             1\n"
          ]
        }
      ],
      "source": [
        "print(dep_var_iris[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "assisted-illinois",
      "metadata": {
        "id": "assisted-illinois",
        "outputId": "888b3207-3cc2-4e9e-e97b-aae0f05280fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.33676526, -0.45038068, -0.0144235 ],\n",
              "        [ 0.6406141 , -0.2510822 , -0.763229  ],\n",
              "        [-0.05308026,  1.0081924 ,  1.0501297 ],\n",
              "        [-0.22489521,  0.10058852, -0.05913624]], dtype=float32),\n",
              " array([ 0.6190525 ,  0.41109788, -0.62422806], dtype=float32)]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 가중치 출력\n",
        "model_iris.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pacific-annex",
      "metadata": {
        "id": "pacific-annex"
      },
      "source": [
        "# 위의 결과를 참고해보면\n",
        "## setosa 의 공식은\n",
        "## y1 = -0.33676526x1 + 0.6406141x2 + (-0.05308026x3) + (-0.22489521)x4 +  0.6190525\n",
        "\n",
        "### 이런 식으로 위의 값들을 참고하여 나머지 두 꽃의 종류에 대해서도 y 식을 만들 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "analyzed-luther",
      "metadata": {
        "id": "analyzed-luther"
      },
      "source": [
        "# Hidden layer\n",
        "## 보스턴 집값 모델 구조 예시 들기\n",
        "## 은닉 계층 사용 시, 좀 더 나은 모델을 만들 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "understood-finger",
      "metadata": {
        "id": "understood-finger"
      },
      "outputs": [],
      "source": [
        "# X = tf.keras.layers.Input(shape=[13])\n",
        "# H = tf.keras.layers.Dense(5, activation = 'swish')(X) # 히든 레이어 생성 5개의 노드 가짐\n",
        "# Y = tf.keras.layers.Dense(1)(H) # 위에선 X로 했지만 이 경우엔 Hidden layer가 중간에 있으므로 H로 실행\n",
        "# model = tf.keras.models.Model(X,Y)\n",
        "# model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sustained-shannon",
      "metadata": {
        "id": "sustained-shannon"
      },
      "outputs": [],
      "source": [
        "# 모델 구조\n",
        "X = tf.keras.layers.Input(shape=[13])\n",
        "H = tf.keras.layers.Dense(10, activation = 'swish')(X) # 히든 레이어 생성 10개의 노드 가짐\n",
        "Y = tf.keras.layers.Dense(1)(H) \n",
        "model_h = tf.keras.models.Model(X,Y)\n",
        "model_h.compile(loss='mse')\n",
        "\n",
        "# 모델 fit 하기\n",
        "model_h.fit(ind_var_boston, dep_var_boston,epochs=1000, verbose=0)\n",
        "model_h.fit(ind_var_boston, dep_var_boston,epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viral-bangladesh",
      "metadata": {
        "id": "viral-bangladesh",
        "outputId": "f6589db3-d974-4403-b80a-6c0bf706b2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 13)]              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 151\n",
            "Trainable params: 151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_h.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "liquid-richmond",
      "metadata": {
        "id": "liquid-richmond",
        "outputId": "bcfc319c-c1f3-44e2-e00e-0d27bf48a3bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[29.33384 ]\n",
            " [24.008694]\n",
            " [30.60481 ]\n",
            " [29.43706 ]\n",
            " [28.945059]]\n",
            "   medv\n",
            "0  24.0\n",
            "1  21.6\n",
            "2  34.7\n",
            "3  33.4\n",
            "4  36.2\n"
          ]
        }
      ],
      "source": [
        "# 예측값과 실제값 비교\n",
        "print(model_h.predict(ind_var_boston[:5]))\n",
        "print(dep_var_boston[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mounted-secretariat",
      "metadata": {
        "id": "mounted-secretariat"
      },
      "source": [
        "# Iris classification using hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "binding-postcard",
      "metadata": {
        "id": "binding-postcard",
        "outputId": "653fca7b-6622-4e22-98f5-82cf5656d97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.5667\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.6600\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0102 - accuracy: 0.6600\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9837 - accuracy: 0.6600\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9579 - accuracy: 0.6733\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9311 - accuracy: 0.6867\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9040 - accuracy: 0.6867\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8780 - accuracy: 0.7533\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8252 - accuracy: 0.7600\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7977 - accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7722 - accuracy: 0.8133\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.8533\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.7733\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.8067\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.8600\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.8200\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.8067\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9000\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.8533\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.8600\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.8467\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.8600\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8667\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8933\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.9133\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.9600\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.9733\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.9533\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.9800\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.9800\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.9733\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.9800\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3293 - accuracy: 0.9733\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.9733\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.9800\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.9800\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9733\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.9800\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.9800\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9667\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9733\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9733\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9733\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2111 - accuracy: 0.9733\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9800\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9800\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9800\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9800\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9800\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9733\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9800\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9800\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9667\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1442 - accuracy: 0.9733\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9733\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9800\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9733\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9733\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9733\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9800\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9733\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9800\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9733\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9667\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9800\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9800\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9733\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1028 - accuracy: 0.9733\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9733\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0940 - accuracy: 0.9800\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9800\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0979 - accuracy: 0.9667\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9733\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9800\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9733\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9800\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9667\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0898 - accuracy: 0.9800\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9733\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0858 - accuracy: 0.9733\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9733\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9800\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9733\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9800\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9733\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9667\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9800\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9800\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9800\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 752us/step - loss: 0.0756 - accuracy: 0.9800\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9733\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9733\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0816 - accuracy: 0.9667\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0746 - accuracy: 0.9800\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9733\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9733\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9800\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0767 - accuracy: 0.9733\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1f0feef3310>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = tf.keras.layers.Input(shape=[4])\n",
        "H1 = tf.keras.layers.Dense(8, activation = 'swish')(X)\n",
        "H2 = tf.keras.layers.Dense(8, activation = 'swish')(H1)\n",
        "H3 = tf.keras.layers.Dense(8, activation = 'swish')(H2)\n",
        "Y = tf.keras.layers.Dense(3,activation='softmax')(H3)\n",
        "model_iris_h = tf.keras.models.Model(X,Y)\n",
        "model_iris_h.compile(loss = 'categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "model_iris_h.fit(ind_var_iris, dep_var_iris,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "medieval-thickness",
      "metadata": {
        "id": "medieval-thickness",
        "outputId": "75a9b6d3-99a3-4478-a9e9-88f9a4b4beff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[9.9986959e-01 1.3036665e-04 3.2253006e-10]\n",
            " [9.9878973e-01 1.2103285e-03 6.7669834e-09]\n",
            " [9.9964035e-01 3.5966377e-04 2.0987754e-09]\n",
            " [9.9920470e-01 7.9535437e-04 7.4284316e-09]\n",
            " [9.9991715e-01 8.2834711e-05 2.2367309e-10]]\n",
            "   품종_setosa  품종_versicolor  품종_virginica\n",
            "0          1              0             0\n",
            "1          1              0             0\n",
            "2          1              0             0\n",
            "3          1              0             0\n",
            "4          1              0             0\n"
          ]
        }
      ],
      "source": [
        "print(model_iris_h.predict(ind_var_iris[:5]))\n",
        "print(dep_var_iris[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incorporate-singles",
      "metadata": {
        "id": "incorporate-singles"
      },
      "source": [
        "# 데이터 타입 조정\n",
        "## 변수를 범주형 데이터로 바꾸기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "incorporate-logan",
      "metadata": {
        "id": "incorporate-logan",
        "outputId": "742888c4-2f8e-456d-e54a-82eee4dc669f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭  품종\n",
              "0     5.1  3.5    1.4   0.2   0\n",
              "1     4.9  3.0    1.4   0.2   0\n",
              "2     4.7  3.2    1.3   0.2   0\n",
              "3     4.6  3.1    1.5   0.2   0\n",
              "4     5.0  3.6    1.4   0.2   0\n",
              "..    ...  ...    ...   ...  ..\n",
              "145   6.7  3.0    5.2   2.3   2\n",
              "146   6.3  2.5    5.0   1.9   2\n",
              "147   6.5  3.0    5.2   2.0   2\n",
              "148   6.2  3.4    5.4   2.3   2\n",
              "149   5.9  NaN    5.1   1.8   2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = 'https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/iris2.csv'\n",
        "new_iris = pd.read_csv(path)\n",
        "new_iris\n",
        "# 품종 수치화 데이터를 범주형 데이터로 바꿔줘야함\n",
        "# 이 경우엔 원래 쓰던 pd.get_dummies를 처음부터 쓸 수 없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "right-advance",
      "metadata": {
        "id": "right-advance",
        "outputId": "aacafaee-4de6-4e85-99e2-35aeaac5fc32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "꽃잎길이      float64\n",
              "꽃잎폭       float64\n",
              "꽃받침길이     float64\n",
              "꽃받침폭      float64\n",
              "품종       category\n",
              "dtype: object"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 원핫인코딩 전에 타입을 category로 버꿔줌\n",
        "new_iris['품종'] = new_iris['품종'].astype('category')\n",
        "new_iris.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continued-coordination",
      "metadata": {
        "id": "continued-coordination",
        "outputId": "7899352b-0bba-4f7c-d373-4f64162b9146"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종_0</th>\n",
              "      <th>품종_1</th>\n",
              "      <th>품종_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭  품종_0  품종_1  품종_2\n",
              "0     5.1  3.5    1.4   0.2     1     0     0\n",
              "1     4.9  3.0    1.4   0.2     1     0     0\n",
              "2     4.7  3.2    1.3   0.2     1     0     0\n",
              "3     4.6  3.1    1.5   0.2     1     0     0\n",
              "4     5.0  3.6    1.4   0.2     1     0     0\n",
              "..    ...  ...    ...   ...   ...   ...   ...\n",
              "145   6.7  3.0    5.2   2.3     0     0     1\n",
              "146   6.3  2.5    5.0   1.9     0     0     1\n",
              "147   6.5  3.0    5.2   2.0     0     0     1\n",
              "148   6.2  3.4    5.4   2.3     0     0     1\n",
              "149   5.9  NaN    5.1   1.8     0     0     1\n",
              "\n",
              "[150 rows x 7 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 원핫인코딩\n",
        "new_iris = pd.get_dummies(new_iris)\n",
        "new_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "honey-rates",
      "metadata": {
        "id": "honey-rates",
        "outputId": "e1d87c3e-0fb7-41a9-8566-5e5336da7fec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "꽃잎길이     0\n",
              "꽃잎폭      1\n",
              "꽃받침길이    0\n",
              "꽃받침폭     0\n",
              "품종_0     0\n",
              "품종_1     0\n",
              "품종_2     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# na 값 체크\n",
        "new_iris.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smaller-operation",
      "metadata": {
        "id": "smaller-operation",
        "outputId": "2f65df25-3d13-40d5-eb59-01793ee6563f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종_0</th>\n",
              "      <th>품종_1</th>\n",
              "      <th>품종_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.054362</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     꽃잎길이       꽃잎폭  꽃받침길이  꽃받침폭  품종_0  품종_1  품종_2\n",
              "145   6.7  3.000000    5.2   2.3     0     0     1\n",
              "146   6.3  2.500000    5.0   1.9     0     0     1\n",
              "147   6.5  3.000000    5.2   2.0     0     0     1\n",
              "148   6.2  3.400000    5.4   2.3     0     0     1\n",
              "149   5.9  3.054362    5.1   1.8     0     0     1"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# na 값에 꽃입폭 평균값 넣어주기\n",
        "mean = new_iris['꽃잎폭'].mean()\n",
        "new_iris['꽃잎폭'] = new_iris['꽃잎폭'].fillna(mean)\n",
        "new_iris.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "differential-episode",
      "metadata": {
        "id": "differential-episode"
      },
      "source": [
        "# 모델 만들기 부록\n",
        "## Batch Normalization\n",
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "federal-taiwan",
      "metadata": {
        "id": "federal-taiwan"
      },
      "source": [
        "## Boston housing price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acknowledged-fantasy",
      "metadata": {
        "id": "acknowledged-fantasy",
        "outputId": "a483a289-b787-4604-f7ac-3ee776b03857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'b', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = 'https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/boston.csv'\n",
        "boston = pd.read_csv(path)\n",
        "boston.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acquired-option",
      "metadata": {
        "id": "acquired-option"
      },
      "outputs": [],
      "source": [
        "ind = boston[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
        "       'ptratio', 'b', 'lstat']]\n",
        "dep = boston[['medv']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plain-memphis",
      "metadata": {
        "id": "plain-memphis"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 만들기\n",
        "X = tf.keras.layers.Input(shape=[13])\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(X)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "model = tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "covered-charity",
      "metadata": {
        "id": "covered-charity"
      },
      "outputs": [],
      "source": [
        "# 모델 구조에 BatchNormilzation layer 추가\n",
        "X = tf.keras.layers.Input(shape=[13])\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "model = tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gorgeous-annotation",
      "metadata": {
        "id": "gorgeous-annotation",
        "outputId": "ccdc7001-0da7-40d4-f76a-edb6f0094320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.9202\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 13.1413\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.0985\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 9.6942\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 8.2518\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 9.2534\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 7.7465\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.7712\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.5346\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.5898\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.7704\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.0117\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.9299\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.4184\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.5733\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.2225\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.8651\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.7009\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.4391\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.7363\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 1000us/step - loss: 10.0367\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.7259\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.4390\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.5371\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.8806\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.7548\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.7603\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 936us/step - loss: 8.4060\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.0325\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.1526\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.7516\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.2016\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 1000us/step - loss: 8.9310\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.3637\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.4152\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.6066\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 933us/step - loss: 8.7942\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.2747\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.8461\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.9507\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.9547\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.6618\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.6171\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.8450\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.2918\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.4821\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.8662\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.6704\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.4687\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.3760\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.0333\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.7207\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.4449\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.6333\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.1009\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.1730\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.9055\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.5807\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 933us/step - loss: 8.5435\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.0506\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.0653\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 6.8065\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.4334\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.0006\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.5965\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.5848\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.6454\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.6902\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.6127\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.8066\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 933us/step - loss: 7.9350\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.0874\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.9623\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.4047\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 1000us/step - loss: 8.7919\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.4966\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 6.7769\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.9286\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.1413\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.1318\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.5054\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 12.2064\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.1859\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.1633\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.8572\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.4598\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.8575\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.4818\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.4611\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.3327\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.1228\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.4510\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 1000us/step - loss: 10.4325\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.9898\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.9497\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.9672\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.7130\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 933us/step - loss: 8.5269\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.7126\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.7244\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1f08c6bd580>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(ind,dep,epochs=1000,verbose=0)\n",
        "model.fit(ind,dep,epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dangerous-tract",
      "metadata": {
        "id": "dangerous-tract"
      },
      "source": [
        "## iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verbal-receptor",
      "metadata": {
        "id": "verbal-receptor",
        "outputId": "441bc22a-db36-4471-ec59-9e81fa2f8db5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n",
              "       '품종_virginica'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = 'https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/iris.csv'\n",
        "iris = pd.read_csv(path)\n",
        "iris = pd.get_dummies(iris)\n",
        "iris.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "operational-brazilian",
      "metadata": {
        "id": "operational-brazilian"
      },
      "outputs": [],
      "source": [
        "ind = iris[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "dep = iris[['품종_setosa', '품종_versicolor',\n",
        "       '품종_virginica']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opponent-department",
      "metadata": {
        "id": "opponent-department",
        "outputId": "ec1d2cc8-3baf-481c-cf23-8a0eb5298481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 1.1010 - accuracy: 0.5200\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0314 - accuracy: 0.6067\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0159 - accuracy: 0.6000\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9763 - accuracy: 0.6333\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.6400\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9056 - accuracy: 0.6333\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8915 - accuracy: 0.6400\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8777 - accuracy: 0.6133\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8414 - accuracy: 0.6267\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8267 - accuracy: 0.6267\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8151 - accuracy: 0.6133\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8082 - accuracy: 0.5867\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7847 - accuracy: 0.6067\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7655 - accuracy: 0.6400\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6133\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.6267\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.6067\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.6467\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6400\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.6733\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.7000\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.7000\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.7400\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.7333\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.7467\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7667\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.7667\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7600\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7400\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.5604 - accuracy: 0.7667\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7800\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7867\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.5425 - accuracy: 0.7800\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7600\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7933\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8000\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8133\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8200\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.8067\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8267\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8000\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8067\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7933\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8133\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8200\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8133\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.8133\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.4409 - accuracy: 0.8133\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8200\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.8333\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8267\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8133\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8000\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.8333\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8067\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8267\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8400\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8267\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.8400\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8333\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8333\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8267\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8400\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8400\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8400\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8400\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8733\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.3673 - accuracy: 0.8333\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3790 - accuracy: 0.8333\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 998us/step - loss: 0.3691 - accuracy: 0.8333\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8533\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8600\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3685 - accuracy: 0.8667\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3614 - accuracy: 0.8533\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3510 - accuracy: 0.8600\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8600\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3433 - accuracy: 0.8667\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8800\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8667\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8867\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.3404 - accuracy: 0.8667\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8933\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8800\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8600\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8667\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8200\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.9067\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3123 - accuracy: 0.9067\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8800\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.9000\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.9000\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.3205 - accuracy: 0.8800\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.3147 - accuracy: 0.9067\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3111 - accuracy: 0.8933\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3085 - accuracy: 0.9133\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8800\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8800\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.9267\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2770 - accuracy: 0.9333\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8733\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.3397 - accuracy: 0.8467\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.9133\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.9200\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2711 - accuracy: 0.9400\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.9000\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.9000\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2899 - accuracy: 0.8933\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8933\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2656 - accuracy: 0.9267\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.9400\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2669 - accuracy: 0.9067\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2639 - accuracy: 0.9133\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2897 - accuracy: 0.9067\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.9200\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.9067\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.9000\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.9067\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.9133\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8800\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.9200\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.9067\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2458 - accuracy: 0.9333\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9400\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2557 - accuracy: 0.9267\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9200\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 749us/step - loss: 0.2401 - accuracy: 0.9267\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9267\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 998us/step - loss: 0.2373 - accuracy: 0.9333\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9467\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9267\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2604 - accuracy: 0.9200\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.9200\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9467\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9333\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.2366 - accuracy: 0.9200\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9267\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9333\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9333\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9467\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9533\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.9000\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9267\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9467\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9400\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2138 - accuracy: 0.9333\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9267\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8933\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2084 - accuracy: 0.9600\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2330 - accuracy: 0.9200\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.9333\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2453 - accuracy: 0.8933\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2007 - accuracy: 0.9600\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2046 - accuracy: 0.9533\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.9267\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9400\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2044 - accuracy: 0.9467\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2027 - accuracy: 0.9467\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2160 - accuracy: 0.9533\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2297 - accuracy: 0.9200\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.9533\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9133\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 751us/step - loss: 0.2321 - accuracy: 0.9267\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9533\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9733\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.9533\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2179 - accuracy: 0.9400\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1785 - accuracy: 0.9533\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9200\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9333\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9400\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9467\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9467\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9600\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1822 - accuracy: 0.9467\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9667\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9200\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9467\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1776 - accuracy: 0.9600\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9467\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 751us/step - loss: 0.1723 - accuracy: 0.9667\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9067\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1852 - accuracy: 0.9667\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9733\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.9600\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1822 - accuracy: 0.9533\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9467\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2037 - accuracy: 0.9400\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9533\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2187 - accuracy: 0.9200\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9533\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9600\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.2013 - accuracy: 0.9400\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9667\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2051 - accuracy: 0.9467\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9733\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9600\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1899 - accuracy: 0.9600\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2151 - accuracy: 0.9267\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9333\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 997us/step - loss: 0.1706 - accuracy: 0.9467\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9533\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9200\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1934 - accuracy: 0.9333\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1650 - accuracy: 0.9600\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2109 - accuracy: 0.9267\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.1822 - accuracy: 0.9467\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2084 - accuracy: 0.9200\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9400\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2284 - accuracy: 0.9067\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9733\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9600\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1693 - accuracy: 0.9533\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9800\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9533\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9600\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9467\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9733\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1829 - accuracy: 0.9533\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1545 - accuracy: 0.9667\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9467\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9533\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9533\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9467\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 752us/step - loss: 0.1723 - accuracy: 0.9667\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9667\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1528 - accuracy: 0.9667\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1796 - accuracy: 0.9600\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9667\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9000\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9600\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9600\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1593 - accuracy: 0.9800\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1494 - accuracy: 0.9600\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9600\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9400\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9333\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9600\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9667\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9600\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9333\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9667\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9667\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9533\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9800\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1507 - accuracy: 0.9533\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9533\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9133\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9800\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1376 - accuracy: 0.9733\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9667\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9733\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9533\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9600\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9667\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1685 - accuracy: 0.9400\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2032 - accuracy: 0.9067\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.1568 - accuracy: 0.9600\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9400\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9600\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1878 - accuracy: 0.9067\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9800\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1611 - accuracy: 0.9600\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1463 - accuracy: 0.9600\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9733\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9667\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9733\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9800\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9600\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.9200\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9667\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1389 - accuracy: 0.9533\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9533\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9733\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9067\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9733\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1486 - accuracy: 0.9600\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9667\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2437 - accuracy: 0.8733\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1536 - accuracy: 0.9733\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9533\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1087 - accuracy: 0.9867\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9333\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9667\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9133\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9733\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1196 - accuracy: 0.9867\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9533\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9600\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9600\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9800\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.2189 - accuracy: 0.9000\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1528 - accuracy: 0.9467\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1962 - accuracy: 0.9267\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9600\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9667\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9400\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.9533\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9667\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9533\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9667\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1430 - accuracy: 0.9400\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1112 - accuracy: 0.9667\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9467\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1327 - accuracy: 0.9600\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1627 - accuracy: 0.9400\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1124 - accuracy: 0.9733\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 751us/step - loss: 0.1280 - accuracy: 0.9733\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9800\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9600\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.9533\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1133 - accuracy: 0.9667\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9667\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1271 - accuracy: 0.9600\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1895 - accuracy: 0.9267\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1292 - accuracy: 0.9667\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 751us/step - loss: 0.1048 - accuracy: 0.9733\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1264 - accuracy: 0.9667\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1056 - accuracy: 0.9733\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9467\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9333\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1658 - accuracy: 0.9267\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1397 - accuracy: 0.9467\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1553 - accuracy: 0.9533\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9400\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1172 - accuracy: 0.9667\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9867\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9733\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1186 - accuracy: 0.9667\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9600\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1142 - accuracy: 0.9533\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9400\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9667\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1005 - accuracy: 0.9800\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9600\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1414 - accuracy: 0.9400\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9667\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1152 - accuracy: 0.9733\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9600\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1011 - accuracy: 0.9933\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9667\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9133\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1086 - accuracy: 0.9733\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0997 - accuracy: 0.9667\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0948 - accuracy: 0.9800\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9600\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9600\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9333\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9467\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1294 - accuracy: 0.9467\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0994 - accuracy: 0.9800\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9467\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9267\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9800\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1222 - accuracy: 0.9667\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9733\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1333 - accuracy: 0.9667\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9600\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0910 - accuracy: 0.9800\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9400\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1055 - accuracy: 0.9600\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9667\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1020 - accuracy: 0.9800\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9267\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9200\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9667\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9667\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9867\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9333\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9667\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1279 - accuracy: 0.9600\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9667\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1202 - accuracy: 0.9600\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9600\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9733\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9533\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1531 - accuracy: 0.9467\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9533\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1266 - accuracy: 0.9600\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9733\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9533\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9533\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9667\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0940 - accuracy: 0.9800\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1147 - accuracy: 0.9667\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0977 - accuracy: 0.9733\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9800\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9600\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9733\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9800\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9400\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1078 - accuracy: 0.9733\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9867\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9733\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9067\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9867\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9400\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9333\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9667\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9600\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9667\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9067\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9933\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9667\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1246 - accuracy: 0.9600\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1095 - accuracy: 0.9667\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9867\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0948 - accuracy: 0.9867\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1201 - accuracy: 0.9733\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0964 - accuracy: 0.9800\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0816 - accuracy: 0.9800\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9733\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8667\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9400\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9800\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9333\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9667\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9467\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8467\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0955 - accuracy: 0.9800\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9533\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9667\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0953 - accuracy: 0.9733\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1179 - accuracy: 0.9333\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9467\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1669 - accuracy: 0.9200\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0929 - accuracy: 0.9867\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0881 - accuracy: 0.9733\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9600\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9533\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1422 - accuracy: 0.9533\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9733\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0987 - accuracy: 0.9533\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1176 - accuracy: 0.9533\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9667\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0850 - accuracy: 0.9667\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9867\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9333\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9867\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1272 - accuracy: 0.9533\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0978 - accuracy: 0.9733\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9267\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1166 - accuracy: 0.9733\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9333\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 998us/step - loss: 0.0899 - accuracy: 0.9867\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9800\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0993 - accuracy: 0.9667\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9800\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9800\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9733\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 997us/step - loss: 0.1132 - accuracy: 0.9667\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9733\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9800\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9467\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9600\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9267\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9733\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9733\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9733\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9600\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1117 - accuracy: 0.9600\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9267\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0984 - accuracy: 0.9733\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9333\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0893 - accuracy: 0.9800\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0764 - accuracy: 0.9733\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.8867\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9200\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9400\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9667\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0751 - accuracy: 0.9800\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0816 - accuracy: 0.9733\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0867 - accuracy: 0.9733\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9667\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0872 - accuracy: 0.9733\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9533\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0687 - accuracy: 0.9733\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1369 - accuracy: 0.9600\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0930 - accuracy: 0.9600\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9533\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1245 - accuracy: 0.9400\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1658 - accuracy: 0.9333\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9867\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0756 - accuracy: 0.9867\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9533\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1644 - accuracy: 0.9067\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9667\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0846 - accuracy: 0.9733\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9600\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9733\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9733\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9867\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1691 - accuracy: 0.9200\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9733\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9400\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9600\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0798 - accuracy: 0.9800\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9067\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9733\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1391 - accuracy: 0.9467\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9600\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1516 - accuracy: 0.9333\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9800\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1030 - accuracy: 0.9667\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 749us/step - loss: 0.1767 - accuracy: 0.9333\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1010 - accuracy: 0.9800\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9333\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9800\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1568 - accuracy: 0.9200\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9467\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9800\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9400\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9400\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9667\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9667\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.0917 - accuracy: 0.9733\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9667\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1151 - accuracy: 0.9600\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9067\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0846 - accuracy: 0.9667\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0748 - accuracy: 0.9933\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9800\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9667\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1141 - accuracy: 0.9533\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1033 - accuracy: 0.9467\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9800\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0751 - accuracy: 0.9800\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9533\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1359 - accuracy: 0.9400\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9600\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1383 - accuracy: 0.9533\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9600\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1838 - accuracy: 0.9267\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9467\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9600\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9600\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9667\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9733\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9733\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9667\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0807 - accuracy: 0.9667\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9867\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9667\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9267\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9400\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9933\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9667\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9467\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9733\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9267\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9400\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9533\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9667\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9800\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9600\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9800\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9533\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9600\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 752us/step - loss: 0.0948 - accuracy: 0.9467\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9667\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0718 - accuracy: 0.9800\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9733\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0637 - accuracy: 0.9800\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9467\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9800\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9200\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1213 - accuracy: 0.9600\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9533\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0982 - accuracy: 0.9600\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9200\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9533\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9333\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1437 - accuracy: 0.9333\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9733\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0780 - accuracy: 0.9667\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9533\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9867\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9733\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9267\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9800\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0841 - accuracy: 0.9667\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9733\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0705 - accuracy: 0.9800\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9667\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1086 - accuracy: 0.9667\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9600\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9600\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 751us/step - loss: 0.0733 - accuracy: 0.9867\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9600\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9733\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9933\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0984 - accuracy: 0.9667\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9533\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1013 - accuracy: 0.9533\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9533\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9667\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9733\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9867\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9600\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9467\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9733\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9667\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9867\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9667\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9400\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9867\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9600\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9867\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1020 - accuracy: 0.9600\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9800\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9800\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1167 - accuracy: 0.9467\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9600\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0630 - accuracy: 0.9933\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1105 - accuracy: 0.9667\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9800\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9733\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9667\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9733\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9800\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9733\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9733\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0970 - accuracy: 0.9600\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9533\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9733\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9867\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9800\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9733\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1395 - accuracy: 0.9467\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9733\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9667\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9667\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0518 - accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9667\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1021 - accuracy: 0.9733\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9733\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0896 - accuracy: 0.9800\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9733\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0699 - accuracy: 0.9867\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9800\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0786 - accuracy: 0.9667\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9733\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9133\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9800\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9533\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9667\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0701 - accuracy: 0.9733\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 749us/step - loss: 0.0788 - accuracy: 0.9800\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1412 - accuracy: 0.9400\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9733\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9733\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9867\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9800\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0906 - accuracy: 0.9667\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9733\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9733\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9533\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9800\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9600\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9867\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1174 - accuracy: 0.9467\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9667\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0787 - accuracy: 0.9800\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9800\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0757 - accuracy: 0.9733\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9933\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9600\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9800\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9800\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9800\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0587 - accuracy: 0.9800\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9600\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0543 - accuracy: 0.9933\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9467\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9400\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9200\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9533\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9467\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.9533\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9600\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9867\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9667\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9333\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9867\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9800\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9800\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9600\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9600\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9733\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9600\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9867\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9867\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9200\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.9067\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9400\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9667\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9667\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9667\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9800\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9800\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9733\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9800\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9600\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9600\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0795 - accuracy: 0.9533\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9733\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9533\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9467\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9600\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9800\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9800\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9667\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9800\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9600\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0616 - accuracy: 0.9800\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9667\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9600\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0652 - accuracy: 0.9733\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9600\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0689 - accuracy: 0.9733\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9800\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9933\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9467\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9800\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9800\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9467\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9667\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9733\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9667\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9733\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9733\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9733\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9467\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9733\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9533\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9600\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9600\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1049 - accuracy: 0.9533\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9800\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1423 - accuracy: 0.9400\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9667\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0825 - accuracy: 0.9667\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0753 - accuracy: 0.9733\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9867\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0837 - accuracy: 0.9667\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9267\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9600\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9800\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9800\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9600\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0563 - accuracy: 0.9800\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9667\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0855 - accuracy: 0.9733\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0719 - accuracy: 0.9733\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9533\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1115 - accuracy: 0.9400\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8867\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0636 - accuracy: 0.9867\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9533\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9533\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9800\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0985 - accuracy: 0.9667\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9733\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9267\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9733\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0759 - accuracy: 0.9667\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9600\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9800\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9533\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9800\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0914 - accuracy: 0.9800\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9267\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0967 - accuracy: 0.9467\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9667\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0657 - accuracy: 0.9667\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9800\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0570 - accuracy: 0.9800\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9400\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9333\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9800\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9267\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9800\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1015 - accuracy: 0.9667\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9867\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0661 - accuracy: 0.9733\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9200\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0550 - accuracy: 0.9933\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9667\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9467\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9133\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9600\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9733\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9667\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.1238 - accuracy: 0.9467\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9467\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9400\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9733\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9467\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9400\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9867\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9733\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9000\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9933\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9600\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9733\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9600\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9667\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9733\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9600\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9600\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9867\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9600\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9600\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9267\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9800\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9800\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9733\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9867\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9733\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9600\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9800\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9867\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1056 - accuracy: 0.9600\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9733\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9867\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9867\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9667\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9800\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9333\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9800\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9867\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9733\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9800\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9667\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9733\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9867\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9867\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9533\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.2349 - accuracy: 0.8933\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9867\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9600\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0701 - accuracy: 0.9800\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9867\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9600\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.0466 - accuracy: 0.9800\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9867\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9600\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9400\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9800\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9533\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9667\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.1547 - accuracy: 0.9667\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9667\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9533\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9600\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9733\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9733\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9800\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9467\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9533\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9667\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9867\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9867\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 999us/step - loss: 0.1156 - accuracy: 0.9467\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9733\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9800\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0652 - accuracy: 0.9800\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9800\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9867\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9667\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9600\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9867\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0545 - accuracy: 0.9867\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9267\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9733\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0498 - accuracy: 0.9733\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9333\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.9200\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0821 - accuracy: 0.9800\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9533\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9733\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9733\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9867\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9600\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9667\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9733\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9467\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9800\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9667\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9667\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9733\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9867\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9733\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9667\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9533\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9933\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9800\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9733\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9400\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9867\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9733\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9867\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9800\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9800\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9333\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0693 - accuracy: 0.9800\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9800\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9867\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9733\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9333\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9733\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9800\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0631 - accuracy: 0.9800\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9667\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0952 - accuracy: 0.9600\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9533\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9400\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9867\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9733\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9867\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9867\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9467\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1484 - accuracy: 0.9267\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9733\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0589 - accuracy: 0.9733\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9733\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9867\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9800\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9533\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9933\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9733\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9867\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9733\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0661 - accuracy: 0.9933\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9800\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0516 - accuracy: 0.9733\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9733\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9933\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9333\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9533\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9267\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9733\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9600\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9867\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0622 - accuracy: 0.9733\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9467\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9867\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0548 - accuracy: 0.9800\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9733\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9800\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8867\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9667\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 0.9800\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9600\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9667\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9733\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9733\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9800\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1612 - accuracy: 0.9333\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1587 - accuracy: 0.9333\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9733\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9867\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0412 - accuracy: 0.9933\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9400\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9533\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9867\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9733\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0753 - accuracy: 0.9667\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9600\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 750us/step - loss: 0.0737 - accuracy: 0.9733\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9600\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9667\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1187 - accuracy: 0.9533\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9533\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9467\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9667\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9933\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0832 - accuracy: 0.9600\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9600\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9800\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9267\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9733\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9533\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9800\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1137 - accuracy: 0.9400\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9600\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.8933\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9800\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9667\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.1802 - accuracy: 0.9333\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9667\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9267\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9467\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9600\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9733\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9733\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9800\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9800\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9200\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 1000us/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1f0ffe01670>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 구조 생성(BatchNormalization 사용)\n",
        "X = tf.keras.layers.Input(shape=[4])\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(3,activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.models.Model(X,Y)\n",
        "model.compile(loss = 'categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "model.fit(ind,dep,epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "roman-prague",
      "metadata": {
        "id": "roman-prague",
        "outputId": "de418f0e-7c70-46d8-e4de-1f1e4b6fc477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_ = [26.1,26.1,26,26.1,26.3,26.6,26.8,27.1,27.3,27.5]\n",
        "len(list_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "excellent-export",
      "metadata": {
        "id": "excellent-export",
        "outputId": "93e6671a-e3ca-4268-8f37-99870c19da03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26.59"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import statistics\n",
        "\n",
        "statistics.mean(list_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coated-burden",
      "metadata": {
        "id": "coated-burden",
        "outputId": "0c3cb676-df15-4716-d313-c9c17a3f58c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2788999999999998"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "statistics.pvariance(list_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "humanitarian-merit",
      "metadata": {
        "id": "humanitarian-merit",
        "outputId": "d2efa244-edf8-4b41-df7a-f23d59548f9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list__ = [21,21,21,27,45,50,49,44,39,36]\n",
        "len(list__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "muslim-horror",
      "metadata": {
        "id": "muslim-horror",
        "outputId": "87e37909-701c-4c8e-c9b7-2a5fec7090fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "127.01"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "statistics.pvariance(list__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manual-indianapolis",
      "metadata": {
        "id": "manual-indianapolis",
        "outputId": "e21ee30e-2ee3-40d0-e097-7e1b6ff04558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11.269871339105872"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "statistics.pstdev(list__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moving-estonia",
      "metadata": {
        "id": "moving-estonia",
        "outputId": "99463ae8-3fcd-435d-e853-49c91990e909"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24.77"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_tmp = [24.2,24.3,24.3,24.2,24.3,24.4,24.6,24.8,25.8,26.8]\n",
        "statistics.mean(list_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "controlling-biography",
      "metadata": {
        "id": "controlling-biography",
        "outputId": "c4187681-2f0b-4d62-81d3-fd9b07c35c0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6661000000000005"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "statistics.pvariance(list_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "willing-roots",
      "metadata": {
        "id": "willing-roots",
        "outputId": "dd62019c-5bcb-4fd0-a770-7e3d0e551721"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8161494961096285"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "statistics.pstdev(list_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "respected-bacteria",
      "metadata": {
        "id": "respected-bacteria"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Tensorflow_101.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "alpha-south",
        "tracked-material",
        "informative-undergraduate",
        "pacific-annex",
        "analyzed-luther"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}